# vim:fileencoding=utf-8
# License: BSD

from utils import make_predicate, array_to_hash, defaults
from errors import SyntaxError, ImportError
from ast import (
AST_Array, AST_Assign, AST_Binary, AST_BlockStatement, AST_Break,
AST_Call, AST_Catch, AST_Class, AST_ClassCall, AST_Conditional, AST_Const,
AST_Constant, AST_Continue, AST_DWLoop, AST_Debugger, AST_Decorator,
AST_Definitions, AST_DictComprehension, AST_Directive, AST_Do, AST_Dot,
AST_EmptyStatement, AST_Except, AST_ExpressiveObject, AST_False, AST_Finally,
AST_ForIn, AST_ForJS, AST_Function, AST_GeneratorComprehension, AST_Hole,
AST_If, AST_Import, AST_ImportedVar, AST_Imports, AST_ListComprehension,
AST_Method, AST_New, AST_Null, AST_Number, AST_Object, AST_ObjectKeyVal,
AST_PropAccess, AST_RegExp, AST_Return, AST_Scope, AST_Set,
AST_SetComprehension, AST_SetItem, AST_Seq, AST_SimpleStatement, AST_Splice,
AST_String, AST_Sub, AST_ItemAccess, AST_SymbolAlias,
AST_SymbolCatch, AST_SymbolConst, AST_SymbolDefun, AST_SymbolFunarg,
AST_SymbolLambda, AST_SymbolNonlocal, AST_SymbolRef, AST_SymbolVar, AST_This,
AST_Throw, AST_Toplevel, AST_True, AST_Try, AST_UnaryPostfix, AST_UnaryPrefix,
AST_Undefined, AST_Var, AST_VarDef, AST_Verbatim, AST_While, AST_With, AST_WithClause,
AST_Yield
)
from tokenizer import tokenizer, is_token, UNARY_POSTFIX


COMPILER_VERSION = '__COMPILER_VERSION__'
BASELIB_ITEMS = {'dir', 'enumerate', 'range', 'reversed', 'getattr', 'setattr', 'hasattr', 'iter',
                 'len', 'abs', 'max', 'min', 'sum', 'map', 'zip', 'filter', 'ord', 'chr', 'callable',
                 'bin', 'hex'}
BASELIB_FUNCS = {'len', 'abs', 'max', 'min'}
BASELIB_ITERTOOLS = {'sum', 'map', 'zip', 'filter'}

NATIVE_CLASSES = {
    'Image': {},
    'RegExp': {},
    'Error': {},
    'EvalError': {},
    'InternalError': {},
    'RangeError': {},
    'ReferenceError': {},
    'SyntaxError': {},
    'TypeError': {},
    'URIError': {},
    'Object': {
        'static': [ "getOwnPropertyNames", "keys", "create", 'defineProperty', 'defineProperties', 'getPrototypeOf', 'setPrototypeOf', 'assign' ]
    },
    'String': {
        'static': [ "fromCharCode" ]
    },
    'Array': {
        'static': [ "isArray", "from", "of" ]
    },
    'Function': {},
    'Date': {
        'static': [ "UTC", "now", "parse" ]
    },
    'ArrayBuffer': {},
    'DataView': {},
    'Float32Array': {},
    'Float64Array': {},
    'Int16Array': {},
    'Int32Array': {},
    'Int8Array': {},
    'Uint16Array': {},
    'Uint32Array': {},
    'Uint8Array': {},
    'Uint8ClampedArray': {},
    'Map': {},
    'WeakMap': {},
    'Set': {},
    'WeakSet': {},
    'XMLHttpRequest': {},
    'TextEncoder': {},
    'TextDecoder': {},
    'MouseEvent': {},
    'Event': {},
    'CustomEvent': {},
    'Blob': {},
}
ERROR_CLASSES = {
    'Exception': {},
    'AttributeError': {},
    'IndexError': {},
    'KeyError': {},
    'ValueError': {},
}
COMMON_STATIC = [ "call", "apply", "bind", "toString" ]

# -----[ Parser (constants) ]-----
UNARY_PREFIX = make_predicate([
    "typeof",
    "void",
    "delete",
    "--",
    "++",
    "!",
    "~",
    "-",
    "+",
    "@"
])


ASSIGNMENT = make_predicate([ "=", "+=", "-=", "/=", "//=", "*=", "%=", ">>=", "<<=", ">>>=", "|=", "^=", "&=" ])

PRECEDENCE = (def(a, ret):
    for i in range(a.length):
        b = a[i]
        for j in range(b.length):
            ret[b[j]] = i+1
    return ret
)([
    # lowest precedence
    [ "||" ],
    [ "&&" ],
    [ "|" ],
    [ "^" ],
    [ "&" ],
    [ "==", "===", "!=", "!==" ],
    [ "<", ">", "<=", ">=", "in", "instanceof" ],
    [ ">>", "<<", ">>>" ],
    [ "+", "-" ],
    [ "*", "/", "//", "%" ],
    [ "**" ]
    # highest precedence
], {})

STATEMENTS_WITH_LABELS = array_to_hash([ "for", "do", "while", "switch" ])

ATOMIC_START_TOKEN = array_to_hash([ "atom", "num", "string", "regexp", "name", "js" ])

compile_time_decorators = ['staticmethod', 'external', 'property']

def has_simple_decorator(decorators, name):
    remove = v'[]'
    for v'var i = 0; i < decorators.length; i++':
        s = decorators[i]
        if isinstance(s, AST_SymbolRef) and not s.parens and s.name is name:
            remove.push(i)
    if remove.length:
        remove.reverse()
        for v'var i = 0; i < remove.length; i++':
            decorators.splice(remove[i], 1)
        return True
    return False

def has_setter_decorator(decorators, name):
    remove = v'[]'
    for v'var i = 0; i < decorators.length; i++':
        s = decorators[i]
        if isinstance(s, AST_Dot) and isinstance(s.expression, AST_SymbolRef) and s.expression.name is name and s.property is 'setter':
            remove.push(i)
    if remove.length:
        remove.reverse()
        for v'var i = 0; i < remove.length; i++':
            decorators.splice(remove[i], 1)
        return True
    return False

# -----[ Parser ]-----
def create_parser_ctx(S, import_dirs, module_id, baselib_items, imported_module_ids, imported_modules, importing_modules, options):

    def next():
        S.prev = S.token
        if S.peeked.length:
            S.token = S.peeked.shift()
        else:
            S.token = S.input()

        S.in_directives = S.in_directives and (S.token.type is "string" or is_("punc", ";"))
        return S.token

    def is_(type, value):
        return is_token(S.token, type, value)

    def peek():
        if not S.peeked.length:
            S.peeked.push(S.input())
        return S.peeked[0]

    def prev():
        return S.prev

    def croak(msg, line, col, pos, is_eof):
        # note: undefined means nothing was passed in, None/null means a null value was passed in
        ctx = S.input.context()
        raise new SyntaxError(msg, ctx.filename, (line is not undefined ? line : ctx.tokline),
                 (col is not undefined ? col : ctx.tokcol), (pos is not undefined ? pos : ctx.tokpos), is_eof)

    def token_error(token, msg):
        is_eof = (token.type is 'eof') ? True : False
        croak(msg, token.line, token.col, undefined, is_eof)

    def unexpected(token):
        if token is undefined:
            token = S.token
        token_error(token, "Unexpected token: " + token.type + " «" + token.value + "»")

    def expect_token(type, val):
        if is_(type, val):
            return next()
        token_error(S.token, "Unexpected token " + S.token.type + " «" + S.token.value + "»" +
                    ", expected " + type + " «" + val + "»")

    def expect(punc):
        return expect_token("punc", punc)

    def can_insert_semicolon():
        return S.token.nlb or is_("eof") or is_("punc", "}")

    def semicolon():
        if is_("punc", ";"):
            next()
            S.token.nlb = True

    def embed_tokens(parser):
        def with_embedded_tokens():
            start = S.token
            expr = parser()
            if expr is undefined:
                unexpected()
            end = prev()
            expr.start = start
            expr.end = end
            return expr
        return with_embedded_tokens

    def scan_for_top_level_callables(body):
        ans = v'[]'
        # Get the named functions and classes
        if Array.isArray(body):
            for obj in body:
                if isinstance(obj, AST_Function) or isinstance(obj, AST_Class):
                    if obj.name:
                        ans.push(obj.name.name)
                    else:
                        token_error(obj.start, "Top-level functions must have names")
                else:
                    # skip inner scopes
                    if isinstance(obj, AST_Scope):
                        continue
                    for x in ['body', 'alternative']:
                        opt = obj[x]
                        if opt:
                            ans = ans.concat(scan_for_top_level_callables(opt))

                        if isinstance(opt, AST_Assign) and not (isinstance(opt.right, AST_Scope)):
                            ans = ans.concat(scan_for_top_level_callables(opt.right))

        elif body.body:
            # recursive descent into wrapper statements that contain body blocks
            ans = ans.concat(scan_for_top_level_callables(body.body))
            if body.alternative:
                ans = ans.concat(scan_for_top_level_callables(body.alternative))


        return ans

    def scan_for_classes(body):
        ans = {}
        for obj in body:
            if isinstance(obj, AST_Class):
                ans[obj.name.name] = obj
        return ans

    def scan_for_local_vars(body):
        """
        Pick out all variables being assigned to from within this scope, we'll mark them as local

        body        body to be scanned
        """
        localvars = v'[]'
        seen = {}

        def push(x):
            if Object.prototype.hasOwnProperty.call(seen, x):
                return
            seen[x] = True
            localvars.push(x)

        def extend(arr):
            for x in arr:
                push(x)

        def scan_in_array(arr):
            for x in arr:
                if isinstance(x, AST_Seq):
                    x = x.to_array()
                    baselib_items['_$rapyd$_flatten'] = True
                elif isinstance(x, AST_Array):
                    x = x.elements
                    baselib_items['_$rapyd$_flatten'] = True
                if Array.isArray(x):
                    scan_in_array(x)
                else:
                    if not isinstance(x, AST_PropAccess):
                        push(x.name)

        def add_assign_lhs(lhs):
            if isinstance(lhs, AST_Seq):
                lhs = new AST_Array({'elements':lhs.to_array()})
            if isinstance(lhs, AST_Array):
                # assignment to an implicit tuple
                push("_$rapyd$_unpack")
                scan_in_array(lhs.elements)
            elif lhs.name:
                # assignment to a single variable
                push(lhs.name)

        def add_for_in(stmt):
            if isinstance(stmt.init, AST_Array):
                # iteration via implicit tuple
                push("_$rapyd$_unpack")
                scan_in_array(stmt.init.elements)
            else:
                # iteration via a single variable
                push(stmt.init.name)

        if Array.isArray(body):
            # this is a body of statements
            for stmt in body:
                # skip inner scopes
                if isinstance(stmt, AST_Scope):
                    continue

                # recursive descent into conditional, loop and exception bodies
                v'[ "body", "alternative" ]'.forEach(def(option):
                    opt = stmt[option]
                    if opt:
                        extend(scan_for_local_vars(opt))

                    if isinstance(opt, AST_Assign) and not (isinstance(opt.right, AST_Scope)):
                        extend(scan_for_local_vars(opt.right))
                )

                # pick up iterators from loops
                if isinstance(stmt, AST_ForIn):
                    add_for_in(stmt)
                elif isinstance(stmt, AST_DWLoop):
                    extend(scan_for_local_vars(stmt))
                elif isinstance(stmt, AST_With):
                    push('_$rapyd$_with_exception'), push('_$rapyd$_with_suppress')
                    for clause in stmt.clauses:
                        if clause.alias:
                            push(clause.alias.name)

        elif body.body:
            # recursive descent into wrapper statements that contain body blocks
            extend(scan_for_local_vars(body.body))
            if body.alternative:
                extend(scan_for_local_vars(body.alternative))

        elif isinstance(body, AST_Assign):
            # this is a single assignment operator
            if body.is_chained():
                for lhs in body.traverse_chain()[0]:
                    add_assign_lhs(lhs)
                push('_$rapyd$_chain_assign_temp')
            else:
                add_assign_lhs(body.left)
            if not isinstance(body.right, AST_Scope):
                extend(scan_for_local_vars(body.right))

        elif isinstance(body, AST_ForIn):
            add_for_in(body)

        return localvars

    def scan_for_nonlocal_defs(body):
        vars = v'[]'
        if Array.isArray(body):
            for stmt in body:
                if isinstance(stmt, AST_Scope):
                    continue

                # don't invade nested scopes
                if isinstance(stmt, AST_Definitions):
                    stmt.definitions.forEach(def(vardef):
                        vars.push(vardef.name.name)
                    )

                v'[ "body", "alternative" ]'.forEach(def(option):
                    nonlocal vars
                    opt = stmt[option]
                    if opt:
                        vars = vars.concat(scan_for_nonlocal_defs(opt))

                )

        elif body.body:
            vars = vars.concat(scan_for_nonlocal_defs(body.body))
            if body.alternative:
                vars = vars.concat(scan_for_nonlocal_defs(body.alternative))


        return vars

    @embed_tokens
    def statement():
        # From Kovid: The next three lines were a hack to try to support statements
        # starting with a regexp literal. However, it did not work, for example:
        # echo 'f=1\n/asd/.test()' | rs -> parse error
        # So we just accept that this cannot be supported in RS, and avoid hacks that mess
        # with the internal state of S. In any case,
        # statements starting with a literal are very rare.
        if S.token.type is 'operator' and S.token.value.substr(0, 1) is '/':
            token_error(S.token, 'RapydScript does not support statements starting with regexp literals')

        S.statement_starting_token = S.token
        tmp_ = S.token.type
        if tmp_ is "string":
            dir = S.in_directives
            stat = simple_statement()
            # XXXv2: decide how to fix directives
            if dir and isinstance(stat.body, AST_String) and not is_("punc", ","):
                return new AST_Directive({
                    'value': stat.body.value
                })

            return stat
        elif tmp_ is "shebang":
            tmp_ = S.token.value
            next()
            return new AST_Directive({
                'value': tmp_
            })
        elif tmp_ is "num" or tmp_ is "regexp" or tmp_ is "operator" or tmp_ is "atom" or tmp_ is "js":
            return simple_statement()
        elif tmp_ is "punc":
            tmp_ = S.token.value
            if tmp_ is ":":
                return new AST_BlockStatement({
                    'start': S.token,
                    'body': block_(),
                    'end': prev()
                })
            elif tmp_ is "{" or tmp_ is "[" or tmp_ is "(":
                return simple_statement()
            elif tmp_ is ";":
                next()
                return new AST_EmptyStatement({'stype':';', 'start':prev(), 'end':prev()})
            else:
                unexpected()
        elif tmp_ is "name":
            if (is_token(peek(), 'punc', ':')) token_error(peek(), 'invalid syntax, colon not allowed here')
            return simple_statement()
        elif tmp_ is "keyword":
            tmp_ = S.token.value
            next()
            if tmp_ is "break":
                return break_cont(AST_Break)
            elif tmp_ is "continue":
                return break_cont(AST_Continue)
            elif tmp_ is "debugger":
                semicolon()
                return new AST_Debugger()
            elif tmp_ is "do":
                return new AST_Do({
                    'body': in_loop(statement),
                    'condition': (def():
                        expect(".")
                        expect_token("keyword", "while")
                        tmp = expression(True)
                        semicolon()
                        return tmp
                    )()
                })
            elif tmp_ is "while":
                return new AST_While({
                    'condition': expression(True),
                    'body': in_loop(statement)
                })
            elif tmp_ is "for":
                if is_('js'):
                    return for_js()
                return for_()
            elif tmp_ is "from":
                return import_(True)
            elif tmp_ is "import":
                return import_(False)
            elif tmp_ is "class":
                baselib_items["extends"] = True
                if options.auto_bind:
                    baselib_items["rebind_all"] = True
                return class_()
            elif tmp_ is "def":
                start = prev()
                func = function_(S.in_class[-1], False)
                func.start = start
                func.end = prev()
                chain = subscripts(func, True)
                if chain is func:
                    return func
                else:
                    return new AST_SimpleStatement({
                        'start': start,
                        'body': chain,
                        'end': prev()
                    })
            elif tmp_ is "if":
                return if_()
            elif tmp_ is "pass":
                semicolon()
                return new AST_EmptyStatement({'stype':'pass', 'start':prev(), 'end':prev()})
            elif tmp_ is "return":
                if S.in_function is 0:
                    croak("'return' outside of function")
                if S.functions[-1].is_generator:
                    croak("'return' not allowed in a function with yield")
                S.functions[-1].is_generator = False

                return new AST_Return({
                    'value': (is_("punc", ";") ?
                        (def():
                            semicolon()
                            return None
                        )() : (can_insert_semicolon() ? None
                            : (def():
                                tmp = expression(True)
                                semicolon()
                                return tmp
                            )()
                        )
                    )
                })
            elif tmp_ is "yield":
                return yield_()
            elif tmp_ is "raise":
                if S.token.nlb:
                    return new AST_Throw({
                        'value': new AST_SymbolCatch({
                            'name': "_$rapyd$_Exception"
                        })
                    })

                tmp = expression(True)
                semicolon()
                return new AST_Throw({
                    'value': tmp
                })
            elif tmp_ is "try":
                return try_()
            elif tmp_ is "nonlocal":
                tmp = nonlocal_()
                semicolon()
                return tmp
            elif tmp_ is "const":
                tmp = const_()
                semicolon()
                return tmp
            elif tmp_ is "with":
                return with_()
            else:
                unexpected()

    def with_():
        clauses = v'[]'
        start = S.token
        while True:
            if is_('eof'):
                unexpected()
            expr = expression()
            alias = None
            if is_('keyword', 'as'):
                next()
                alias = as_symbol(AST_SymbolAlias)
            clauses.push(new AST_WithClause({'expression':expr, 'alias':alias}))
            if is_('punc', ','):
                next()
                continue
            if not is_('punc', ':'):
                unexpected()
            break

        if not clauses.length:
            token_error(start, 'with statement must have at least one clause')
        body = statement()

        return new AST_With({
            'clauses': clauses,
            'body': body
        })

    def simple_statement(tmp):
        tmp = expression(True)
        semicolon()
        return new AST_SimpleStatement({
            'body': tmp
        })

    def break_cont(type):
        if S.in_loop is 0:
            croak(type.TYPE + " not inside a loop or switch")
        semicolon()
        return new type()

    def yield_():
        if S.in_function is 0:
            croak("'yield' outside of function")
        if S.functions[-1].is_generator is False:
            croak("'yield' not allowed in a function with return")
        S.functions[-1].is_generator = True
        is_yield_from = is_('keyword', 'from')
        if is_yield_from:
            next()
        return new AST_Yield({
            'is_yield_from':is_yield_from,
            'value': (is_("punc", ";") ?
                (def():
                    semicolon()
                    return None
                )() : (can_insert_semicolon() ? None
                    : (def():
                        tmp = expression(True)
                        semicolon()
                        return tmp
                    )()
                )
            )
        })

    def for_(list_comp):
        #        expect("(")
        init = None
        if not is_("punc", ";"):
            init = expression(True, True)
            # standardize AST_Seq into array now for consistency
            if isinstance(init, AST_Seq):
                if isinstance(init.car, AST_SymbolRef) and isinstance(init.cdr, AST_SymbolRef):
                    # Optimization to prevent runtime call to _$rapyd$_flatten when init is simply (a, b)
                    tmp = init.to_array()
                else:
                    tmp = [init]
                init = new AST_Array({
                    'start': init.start,
                    'elements': tmp,
                    'end': init.end
                })

            if is_("operator", "in"):
                if isinstance(init, AST_Var) and init.definitions.length > 1:
                    croak("Only one variable declaration allowed in for..in loop")
                next()
                return for_in(init, list_comp)

        unexpected()

    def for_in(init, list_comp):
        lhs = (isinstance(init, AST_Var) ? init.definitions[0].name : None)
        obj = expression(True)
        baselib_items["iterable"] = True
        #        expect(")")
        if list_comp:
            return {
                'init': init,
                'name': lhs,
                'object': obj
            }

        return new AST_ForIn({
            'init': init,
            'name': lhs,
            'object': obj,
            'body': in_loop(statement)
        })

    # A native JavaScript for loop - for v"var i=0; i<5000; i++":
    def for_js():
        condition = as_atom_node()
        return new AST_ForJS({
            'condition': condition,
            'body': in_loop(statement)
        })

    # scan function/class body for nested class declarations
    def get_class_in_scope(expr):
        # TODO: Currently if a local variable shadows a class name defined in
        # an outerscope, the logic below will identify that variable as a
        # class. This bug was always present. Fixing it will require the parser
        # to maintain a list of local variables for every AST_Scope and provide
        # an easy way to walk the ast tree upwards.
        if isinstance(expr, AST_SymbolRef):
            # check Native JS classes
            if NATIVE_CLASSES.hasOwnProperty(expr.name):
                return NATIVE_CLASSES[expr.name]
            if ERROR_CLASSES.hasOwnProperty(expr.name):
                return ERROR_CLASSES[expr.name]

            # traverse in reverse to check local variables first
            for s in range(S.classes.length-1, -1, -1):
                if S.classes[s].hasOwnProperty(expr.name):
                    return S.classes[s][expr.name]

        elif isinstance(expr, AST_Dot):
            referenced_path = []
            # this one is for detecting classes inside modules and eventually nested classes
            while isinstance(expr, AST_Dot):
                referenced_path.unshift(expr.property)
                expr = expr.expression
            if isinstance(expr, AST_SymbolRef):
                referenced_path.unshift(expr.name)
                # now 'referenced_path' should contain the full path of potential class
                if len(referenced_path) > 1:
                    class_name = referenced_path.join('.')
                    for s in range(S.classes.length-1, -1, -1):
                        if S.classes[s].hasOwnProperty(class_name):
                            return S.classes[s][class_name]
        return False

    def import_error(message):
        ctx = S.input.context()
        raise new ImportError(message, ctx.filename, ctx.tokline, ctx.tokcol, ctx.tokpos)

    def do_import(key):
        if imported_modules.hasOwnProperty(key):
            return
        if importing_modules.hasOwnProperty(key) and importing_modules[key]:
            import_error('Detected a recursive import of: ' + key + ' while importing: ' + module_id)

        # Ensure that the package containing this module is also imported
        package_module_id = key.split('.')[:-1].join('.')
        if len(package_module_id) > 0:
            do_import(package_module_id)

        if options.for_linting:
            imported_modules[key] = {'is_cached':True, 'classes':{}, 'module_id':key, 'exports':[],
                             'submodules':[], 'nonlocalvars':[], 'baselib':{}, 'outputs':{}}
            if len(package_module_id) > 0:
                imported_modules[package_module_id].submodules.push(key)
            return

        def safe_read(base_path):
            for i, path in enumerate([base_path + '.pyj', base_path + '/__init__.pyj']):
                try:
                    return [readfile(path, "utf-8"), path]  # noqa:undef
                except as e:
                    if e.code is 'ENOENT' or e.code is 'EPERM' or e.code is 'EACCESS':
                        if i is 1:
                            return None, None
                    if i is 1:
                        raise

        src_code = filename = None
        modpath = key.replace('.', '/')

        for location in import_dirs:
            if location:
                data, filename = safe_read(location + '/' + modpath)
                if data is not None:
                    src_code = data
                    break
        if src_code is None:
            import_error("Failed Import: '" + key + "' module doesn't exist in any of the import directories: " + import_dirs.join(':'))

        try:
            cached = JSON.parse(readfile(filename + '-cached', 'utf-8'))  # noqa:undef
        except:
            cached = None

        srchash = sha1sum(src_code)  # noqa:undef
        if cached and cached['version'] is COMPILER_VERSION and cached['signature'] is srchash:
            for ikey in cached.imported_module_ids:
                do_import(ikey)  # Ensure all modules imported by the cached module are also imported
            imported_modules[key] = {
                'is_cached':True, 'classes':cached['classes'], 'outputs':cached['outputs'], 'module_id':key, 'import_order':Object.keys(imported_modules).length,
                'submodules':[], 'nonlocalvars':cached['nonlocalvars'], 'baselib':cached['baselib'], 'exports':cached.exports
            }
        else:
            parse(src_code, {
                'filename': filename,
                'toplevel': None,
                'basedir': options.basedir,
                'libdir': options.libdir,
                'module_id': key,
                'imported_modules': imported_modules,
                'importing_modules': importing_modules,
            })  # This function will add the module to imported_modules itself

        imported_modules[key].srchash = srchash
        if len(package_module_id) > 0:
            imported_modules[package_module_id].submodules.push(key)

        for bitem in Object.keys(imported_modules[key].baselib):
            baselib_items[bitem] = True
        imported_module_ids.push(key)


    def import_(from_import):
        ans = new AST_Imports({'imports':[]})
        while True:
            tok = tmp = name = last_tok = expression(False)
            key = ''
            while isinstance(tmp, AST_Dot):
                key = "." + tmp.property + key
                tmp = last_tok = tmp.expression
            key = tmp.name + key
            alias = None
            if not from_import and is_('keyword', 'as'):
                next()
                alias = as_symbol(AST_SymbolAlias)
            aimp = new AST_Import({
                'module': name,
                'key': key,
                'alias': alias,
                'argnames':None,
                'body':def():
                    return imported_modules[key]
            })
            aimp.start, aimp.end = tok.start, last_tok.end
            ans.imports.push(aimp)
            if from_import:
                break
            if is_('punc', ','):
                next()
            else:
                break

        for imp in ans['imports']:
            do_import(imp.key)
            classes = imported_modules[key].classes
            if from_import:
                expect_token("keyword", "import")
                imp.argnames = argnames = []
                bracketed = is_('punc', '(')
                if bracketed:
                    next()
                exports = {}
                for symdef in imported_modules[key].exports:
                    exports[symdef.name] = True
                while True:
                    aname = as_symbol(AST_ImportedVar)
                    if not options.for_linting and not exports.hasOwnProperty(aname.name):
                        import_error('The symbol "' + aname.name + '" is not exported from the module: ' + key)
                    if is_('keyword', 'as'):
                        next()
                        aname.alias = as_symbol(AST_SymbolAlias)
                    argnames.push(aname)
                    if is_('punc', ','):
                        next()
                    else:
                        if bracketed:
                            if is_('punc', ')'):
                                next()
                            else:
                                continue
                        break

                # Put imported class names in the outermost scope
                for argvar in argnames:
                    obj = classes[argvar.name]
                    if obj:
                        key = (argvar.alias) ? argvar.alias.name : argvar.name
                        S.classes[-1][key] = { "static": obj.static, 'bound': obj.bound }
            else:
                for cname in Object.keys(classes):
                    obj = classes[cname]
                    key = (imp.alias) ? imp.alias.name : imp.key
                    S.classes[-1][key + '.' + obj.name.name] = { 'static': obj.static, 'bound': obj.bound }

        return ans

    def class_():
        name = as_symbol(AST_SymbolDefun)
        if not name:
            unexpected()

        # detect external classes
        externaldecorator = has_simple_decorator(S.decorators, 'external')

        class_details = {
            "static": [],
            'bound': {}
        }
        definition = new AST_Class({
            'name': name,
            'module_id':module_id,
            'dynamic_properties': {},
            'parent': (def():
                if is_("punc", "("):
                    S.in_parenthesized_expr = True
                    next()
                    if is_('punc', ')'):
                        S.in_parenthesized_expr = False
                        next()
                        return None
                    a = expr_atom(False)
                    expect(")")
                    S.in_parenthesized_expr = False
                    return a
                else:
                    return None
            )(),
            'localvars': [],
            "static": class_details.static,
            'external': externaldecorator,
            'bound': class_details.bound,
            'statements': [],
            'decorators': (def():
                d = []
                S.decorators.forEach(def(decorator):
                    d.push(new AST_Decorator({
                        'expression': decorator
                    }))
                )
                S.decorators = v'[]'
                return d
            )(),
            'body': (def(loop, labels):
                # navigate to correct location in the module tree and append the class
                S.in_class.push(name.name)
                S.classes[S.classes.length - 1][name.name] = class_details
                S.classes.push({})
                S.in_function += 1
                S.in_directives = True
                S.in_loop = 0
                S.labels = []
                a = block_()
                S.in_function -= 1
                S.classes.pop()
                S.in_class.pop()
                S.in_loop = loop
                S.labels = labels
                return a
            )(S.in_loop, S.labels)
        })
        # find the constructor
        for stmt in definition.body:
            if isinstance(stmt, AST_Method):
                if stmt.is_getter or stmt.is_setter:
                    descriptor = definition.dynamic_properties[stmt.name.name]
                    if not descriptor:
                        descriptor = definition.dynamic_properties[stmt.name.name] = {}
                    descriptor['getter' if stmt.is_getter else 'setter'] = stmt
                elif stmt.name.name is "__init__":
                    definition.init = stmt
        # find the class variables
        class_var_names = {}
        # Ensure that if a class variable refers to another class variable in
        # its initialization, the referenced variables' names is correctly
        # mangled.
        def walker():
            def visit_node(node, descend):
                if isinstance(node, AST_Method):
                    class_var_names[node.name.name] = True
                    return
                elif isinstance(node, AST_Assign) and isinstance(node.left, AST_SymbolRef):
                    class_var_names[node.left.name] = True
                elif isinstance(node, AST_SymbolRef) and Object.prototype.hasOwnProperty.call(class_var_names, node.name):
                    node.thedef = new AST_SymbolDefun({'name':name.name + '.prototype.' + node.name})
                if descend:
                    descend.call(node)
            this._visit = visit_node
        visitor = new walker()

        for stmt in definition.body:
            if not isinstance(stmt, AST_Class):
                stmt.walk(visitor)
                definition.statements.push(stmt)
        return definition

    def function_(in_class, is_expression):
        name = (is_("name") ? as_symbol((in_class ? AST_SymbolDefun : AST_SymbolLambda)) : None)
        if in_class and not name:
            unexpected()

        staticmethod = property_getter = property_setter = False
        if in_class:
            staticloc = has_simple_decorator(S.decorators, 'staticmethod')
            property_getter = has_simple_decorator(S.decorators, 'property')
            property_setter = has_setter_decorator(S.decorators, name.name)
            if staticloc:
                if property_getter or property_setter:
                    croak('A method cannot be both static and a property getter/setter')
                S.classes[S.classes.length - 2][in_class].static.push(name.name)
                staticmethod = True
            elif name.name is not "__init__" and options.auto_bind:
                baselib_items["bind"] = True
                S.classes[S.classes.length - 2][in_class].bound[name.name] = True

        expect("(")
        S.in_parenthesized_expr = True
        ctor = in_class ? AST_Method : AST_Function

        is_generator = v'[]'
        definition = new ctor({
            'name': name,
            'is_expression': is_expression,
            'argnames': (def(a):
                defaults = {}
                first = True
                seen_names = {}

                def get_arg():
                    if Object.prototype.hasOwnProperty.call(seen_names, S.token.value):
                        token_error(prev(), "Can't repeat parameter names")
                    if S.token.value is 'arguments':
                        token_error(prev(), "Can't use the name arguments as a parameter name, it is reserved by JavaScript")
                    seen_names[S.token.value] = True
                    return as_symbol(AST_SymbolFunarg)

                while not is_("punc", ")"):
                    if first:
                        first = False
                    else:
                        expect(",")
                        if is_('punc', ')'):
                            break
                    if is_('operator', '**'):
                        # **kwargs
                        next()
                        if a.kwargs:
                            token_error(prev(), "Can't define multiple **kwargs in function definition")
                        a.kwargs = get_arg()
                    elif is_('operator', '*'):
                        # *args
                        next()
                        if a.starargs:
                            token_error(prev(), "Can't define multiple *args in function definition")
                        if a.kwargs:
                            token_error(prev(), "Can't define *args after **kwargs in function definition")
                        a.starargs = get_arg()
                    else:
                        if a.starargs or a.kwargs:
                            token_error(prev(), "Can't define a formal parameter after *args or **kwargs")
                        a.push(get_arg())
                        if is_("operator", "="):
                            if a.kwargs:
                                token_error(prev(), "Can't define an optional formal parameter after **kwargs")
                            val = prev().value
                            next()
                            defaults[val] = expression(False)
                            a.has_defaults = True
                        else:
                            if a.has_defaults:
                                token_error(prev(), "Can't define required formal parameters after optional formal parameters")

                next()
                S.in_parenthesized_expr = False
                a.defaults = defaults
                a.is_simple_func = not a.starargs and not a.kwargs and not a.has_defaults
                return a
            )(v'[]'),
            'localvars': [],
            'decorators': (def():
                d = v'[]'
                S.decorators.forEach(def(decorator):
                    d.push(new AST_Decorator({
                        'expression': decorator
                    }))
                )
                S.decorators = v'[]'
                return d
            )(),
            'body': (def(loop, labels):
                S.in_class.push(False)
                S.classes.push({})
                S.in_function += 1
                S.functions.push({})
                S.in_directives = True
                S.in_loop = 0
                S.labels = []
                a = block_()
                S.in_function -= 1
                is_generator.push(bool(S.functions.pop().is_generator))
                S.classes.pop()
                S.in_class.pop()
                S.in_loop = loop
                S.labels = labels
                return a
            )(S.in_loop, S.labels)
        })
        definition.is_generator = is_generator[0]
        if isinstance(definition, AST_Method):
            definition.static = staticmethod
            definition.is_getter = property_getter
            definition.is_setter = property_setter
            if definition.argnames.length < 1 and not definition.static:
                croak('Methods of a class must have at least one argument, traditionally named self')
            if definition.name and definition.name.name is '__init__':
                if definition.is_generator:
                    croak('The __init__ method of a class cannot be a generator (yield not allowed)')
                if property_getter or property_setter:
                    croak('The __init__ method of a class cannot be a property getter/setter')
        if definition.is_generator:
            baselib_items['yield'] = True

        # detect local variables, strip function arguments
        assignments = scan_for_local_vars(definition.body)
        for i in range(assignments.length):
            for j in range(definition.argnames.length+1):
                if j is definition.argnames.length:
                    definition.localvars.push(new_symbol(AST_SymbolVar, assignments[i]))
                elif j < definition.argnames.length and assignments[i] is definition.argnames[j].name:
                    break

        nonlocals = scan_for_nonlocal_defs(definition.body)
        nonlocals = {name for name in nonlocals}
        definition.localvars = definition.localvars.filter(def(v): return not nonlocals.has(v.name);)
        return definition

    def if_():
        cond = expression(True)
        body = statement()
        belse = None
        if is_("keyword", "elif") or is_("keyword", "else"):
            if is_("keyword", "else"):
                next()
            else:
                S.token.value = "if"
            # effectively converts 'elif' to 'else if'
            belse = statement()

        return new AST_If({
            'condition': cond,
            'body': body,
            'alternative': belse
        })

    def block_():
        expect(":")
        a = v'[]'
        if not S.token.nlb:
            while not S.token.nlb:
                if is_("eof"):
                    unexpected()
                a.push(statement())
        else:
            while not is_("punc", "}"):
                if is_("eof"):
                    # end of file, terminate block automatically
                    return a
                a.push(statement())
            next()
        return a

    def try_():
        body = block_()
        bcatch = []
        bfinally = None
        while is_("keyword", "except"):
            start = S.token
            next()
            exceptions = []
            if not is_("punc", ":") and not is_("keyword", "as"):
                exceptions.push(as_symbol(AST_SymbolVar))
                while is_("punc", ","):
                    next()
                    exceptions.push(as_symbol(AST_SymbolVar))

            name = None
            if is_("keyword", "as"):
                next()
                name = as_symbol(AST_SymbolCatch)

            bcatch.push(new AST_Except({
                'start': start,
                'argname': name,
                'errors': exceptions,
                'body': block_(),
                'end': prev()
            }))

        if is_("keyword", "finally"):
            start = S.token
            next()
            bfinally = new AST_Finally({
                'start': start,
                'body': block_(),
                'end': prev()
            })

        if not bcatch.length and not bfinally:
            croak("Missing except/finally blocks")

        return new AST_Try({
            'body': body,
            'bcatch': (bcatch.length ? new AST_Catch({
                'body': bcatch
            }) : None),
            'bfinally': bfinally
        })

    def vardefs(no_in, in_const, in_nonlocal):
        a = []
        while True:
            a.push(new AST_VarDef({
                'start': S.token,
                'name': as_symbol((in_const ? AST_SymbolConst : ((in_nonlocal) ? AST_SymbolNonlocal : AST_SymbolVar))),
                'value': (is_("operator", "=") ? (next(), expression(False, no_in)) : None),
                'end': prev()
            }))
            if not is_("punc", ","):
                break
            next()

        return a

    def nonlocal_(no_in):
        return new AST_Var({
            'start': prev(),
            'definitions': vardefs(no_in, False, True),
            'end': prev()
        })

    def const_():
        return new AST_Const({
            'start': prev(),
            'definitions': vardefs(False, True),
            'end': prev()
        })

    def new_():
        start = S.token
        expect_token("operator", "new")
        newexp = expr_atom(False)

        if is_("punc", "("):
            S.in_parenthesized_expr = True
            next()
            args = func_call_list()
            S.in_parenthesized_expr = False
        else:
            args = func_call_list(True)
        return subscripts(new AST_New({
            'start': start,
            'expression': newexp,
            'args': args,
            'end': prev()
        }), True)

    def string_():
        strings = v'[]'
        start = S.token
        while True:
            strings.push(S.token.value)
            if peek().type is not 'string':
                break
            next()
        return new AST_String({
            'start': start,
            'end': S.token,
            'value': strings.join('')
        })

    def token_as_atom_node():
        tok = S.token
        tmp_ = tok.type
        if tmp_ is "name":
            return token_as_symbol(tok, AST_SymbolRef)
        elif tmp_ is "num":
            return new AST_Number({
                'start': tok,
                'end': tok,
                'value': tok.value
            })
        elif tmp_ is "string":
            return string_()
        elif tmp_ is "regexp":
            return new AST_RegExp({
                'start': tok,
                'end': tok,
                'value': tok.value
            })
        elif tmp_ is "atom":
            tmp__ = tok.value
            if tmp__ is "False":
                return new AST_False({
                    'start': tok,
                    'end': tok
                })
            elif tmp__ is "True":
                return new AST_True({
                    'start': tok,
                    'end': tok
                })
            elif tmp__ is "None":
                return new AST_Null({
                    'start': tok,
                    'end': tok
                })
        elif tmp_ is "js":
            return new AST_Verbatim({
                'start': tok,
                'end': tok,
                'value': tok.value,
            })
        token_error(tok, 'Expecting an atomic token (number/string/bool/regexp/js/None)')

    def as_atom_node():
        ret = token_as_atom_node()
        next()
        return ret

    def expr_atom(allow_calls):
        if is_("operator", "new"):
            return new_()

        start = S.token
        if is_("punc"):
            tmp_ = start.value
            if tmp_ is "(":
                S.in_parenthesized_expr = True
                next()
                if is_('punc', ')'):
                    next()
                    return new AST_Array({'elements':[]})
                ex = expression(True)
                if is_('keyword', 'for'):
                    ret = read_comprehension(new AST_GeneratorComprehension({'statement': ex}), ')')
                    S.in_parenthesized_expr = False
                    return ret
                ex.start = start
                ex.end = S.token
                if isinstance(ex, AST_SymbolRef):
                    ex.parens = True
                if not isinstance(ex, AST_GeneratorComprehension):
                    expect(")")
                S.in_parenthesized_expr = False
                return subscripts(ex, allow_calls)
            elif tmp_ is "[":
                return subscripts(array_(), allow_calls)
            elif tmp_ is "{":
                return subscripts(object_(), allow_calls)

            unexpected()

        if is_("keyword", "class"):
            next()
            cls = class_()
            cls.start = start
            cls.end = prev()
            return subscripts(cls, allow_calls)

        if is_("keyword", "def"):
            next()
            func = function_(False, True)
            func.start = start
            func.end = prev()
            return subscripts(func, allow_calls)

        if is_('keyword', 'yield'):
            next()
            return yield_()

        if ATOMIC_START_TOKEN[S.token.type]:
            return subscripts(as_atom_node(), allow_calls)

        unexpected()

    def expr_list(closing, allow_trailing_comma, allow_empty, func_call):
        first = True
        a = []
        saw_starargs = False
        while not is_("punc", closing):
            if saw_starargs:
                token_error(prev(), "*args must be the last argument in a function call")

            if first:
                first = False
            else:
                expect(",")
            if allow_trailing_comma and is_("punc", closing):
                break

            if is_("operator", "*") and func_call:
                saw_starargs = True
                next()

            if is_("punc", ",") and allow_empty:
                a.push(new AST_Hole({
                    'start': S.token,
                    'end': S.token
                }))
            else:
                a.push(expression(False))

        if func_call:
            tmp = []
            tmp.kwargs = []
            for arg in a:
                if isinstance(arg, AST_Assign):
                    tmp.kwargs.push([arg.left, arg.right])
                else:
                    tmp.push(arg)
            a = tmp

        next()
        if saw_starargs:
            a.starargs = True
        return a

    def func_call_list(empty):
        a = v'[]'
        first = True
        a.kwargs = v'[]'
        a.kwarg_items = v'[]'
        a.starargs = False
        if empty:
            return a
        single_comprehension = False
        while not is_("punc", ')') and not is_('eof'):
            if not first:
                expect(",")
                if is_('punc', ')'):
                    break
            if is_('operator', '*'):
                next()
                arg = expression(False)
                arg.is_array = True
                a.push(arg)
                a.starargs = True
            elif is_('operator', '**'):
                next()
                a.kwarg_items.push(as_symbol(AST_SymbolRef, False))
                a.starargs = True
            else:
                arg = expression(False)
                if isinstance(arg, AST_Assign):
                    a.kwargs.push([arg.left, arg.right])
                else:
                    if is_('keyword', 'for'):
                        if not first:
                            croak('Generator expression must be parenthesized if not sole argument')
                        a.push(read_comprehension(new AST_GeneratorComprehension({'statement': arg}), ')'))
                        single_comprehension = True
                        break
                    a.push(arg)
            first = False
        if a.kwargs.length:
            baselib_items['_$rapyd$_desugar_kwargs()'] = True
        if not single_comprehension:
            next()
        return a

    @embed_tokens
    def array_():
        expect("[")
        expr = []
        if not is_("punc", "]"):
            expr.push(expression(False))
            if is_("keyword", "for"):
                # list comprehension
                return read_comprehension(new AST_ListComprehension({'statement': expr[0]}), ']')

            if not is_("punc", "]"):
                expect(",")

        return new AST_Array({
            'elements': expr.concat(expr_list("]", True, True))
        })

    @embed_tokens
    def object_():
        expect("{")
        first = True
        has_non_const_keys = False
        is_pydict = False
        a = []
        if is_('punc', '!'):
            next()
            is_pydict = True
        while not is_("punc", "}"):
            if not first:
                expect(",")
            if is_("punc", "}"):
                # allow trailing comma
                break
            first = False

            start = S.token
            ctx = S.input.context()
            orig = ctx.expecting_object_literal_key
            ctx.expecting_object_literal_key = True
            try:
                left = expression(False)
            finally:
                ctx.expecting_object_literal_key = orig
            if is_('keyword', 'for'):
                # is_pydict is irrelevant here
                return read_comprehension(new AST_SetComprehension({'statement':left}), '}')
            if a.length is 0 and (is_('punc', ',') or is_('punc', '}')):
                end = prev()
                return set_(start, end, left)
            if not isinstance(left, AST_Constant):
                has_non_const_keys = True
            expect(":")
            a.push(new AST_ObjectKeyVal({
                'start': start,
                'key': left,
                'value': expression(False),
                'end': prev()
            }))
            if a.length is 1 and is_('keyword', 'for'):
                return dict_comprehension(a, is_pydict)

        next()
        return new (has_non_const_keys ? AST_ExpressiveObject : AST_Object)({
            'properties': a,
            'is_pydict': is_pydict,
        })

    def set_(start, end, expr):
        ostart = start
        a = [new AST_SetItem({'start':start, 'end':end, 'value':expr})]
        while not is_("punc", "}"):
            expect(",")
            start = S.token
            if is_("punc", "}"):
                # allow trailing comma
                break
            a.push(new AST_SetItem({'start':start, 'value':expression(False), 'end':prev()}))
        next()
        return new AST_Set({'items':a, 'start':ostart, 'end':prev()})

    def read_comprehension(obj, terminator):
        if isinstance(obj, AST_GeneratorComprehension):
            baselib_items['yield'] = True
        S.in_comprehension = True
        S.in_parenthesized_expr = False  # in case we are already in a parenthesized expression
        expect_token('keyword', 'for')
        forloop = for_(True)
        baselib_items["iterable"] = True
        obj.init = forloop.init
        obj.name = forloop.name
        obj.object = forloop.object
        obj.condition = (is_("punc", terminator) ? None : (expect_token("keyword", "if"), expression(True)))
        expect(terminator)
        S.in_comprehension = False
        return obj

    def dict_comprehension(a, is_pydict):
        if a.length:
            left, right = a[0].key, a[0].value
        else:
            left = expression(False)
            if not is_('punc', ':'):
                return read_comprehension(new AST_SetComprehension({'statement':left}), '}')
            expect(':')
            right = expression(False)
        return read_comprehension(new AST_DictComprehension({'statement':left, 'value_statement':right, 'is_pydict':is_pydict}), '}')

    def as_name():
        tmp = S.token
        next()
        tmp_ = tmp.type
        if tmp_ is "name" or tmp_ is "operator" or tmp_ is "keyword" or tmp_ is "atom":
            return tmp.value
        else:
            unexpected()

    def token_as_symbol(tok, ttype):
        name = tok.value
        return new ((name is "this" ? AST_This : ttype))({
            'name': v"String(tok.value)",
            'start': tok,
            'end': tok
        })

    def as_symbol(ttype, noerror):
        if not is_("name"):
            if not noerror:
                croak("Name expected")
            return None

        sym = token_as_symbol(S.token, ttype)
        next()
        return sym

    # for generating/inserting a new symbol
    def new_symbol(type, name):
        sym = new ((name is "this" ? AST_This : type))({
            'name': v"String(name)",
            'start': None,
            'end': None
        })
        return sym

    def is_static_method(cls, method):
        if COMMON_STATIC.indexOf(method) is not -1 or cls.static and cls.static.indexOf(method) is not -1:
            return True
        else:
            return False

    def subscripts(expr, allow_calls):
        start = expr.start
        if is_("punc", "."):
            next()
            return subscripts(new AST_Dot({
                'start': start,
                'expression': expr,
                'property': as_name(),
                'end': prev()
            }), allow_calls)

        if is_("punc", "[") and not S.token.nlb:
            next()
            is_py_sub = False
            if is_('punc', '!'):
                next()
                is_py_sub = True
            slice_bounds = []
            is_slice = False
            if is_("punc", ":"):
                # slice [:n]
                slice_bounds.push(None)
            else:
                slice_bounds.push(expression(False))

            if is_("punc", ":"):
                # slice [n:m?]
                is_slice = True
                next()
                if is_("punc", ":"):
                    slice_bounds.push(None)
                elif not is_("punc", "]"):
                    slice_bounds.push(expression(False))

            if is_("punc", ":"):
                # slice [n:m:o?]
                next()
                if is_("punc", "]"):
                    unexpected()
                else:
                    slice_bounds.push(expression(False))

            expect("]")

            if is_slice:
                if is_("operator") and S.token.value is "=":
                    # splice-assignment (arr[start:end] = ...)
                    next()  # swallow the assignment
                    return subscripts(new AST_Splice({
                        'start': start,
                        'expression': expr,
                        'property': slice_bounds[0] or new AST_Number({
                            'value': 0
                        }),
                        'property2': slice_bounds[1],
                        'assignment': expression(True),
                        'end': prev()
                    }), allow_calls)
                elif slice_bounds.length is 3:
                    # extended slice (arr[start:end:step])
                    slice_bounds.unshift(slice_bounds.pop())
                    if not slice_bounds[-1]:
                        slice_bounds.pop()
                        if not slice_bounds[-1]:
                            slice_bounds.pop()
                    elif not slice_bounds[-2]:
                        slice_bounds[-2] = new AST_Undefined()

                    return subscripts(new AST_Call({
                        'start': start,
                        'expression': new AST_SymbolRef({
                            'name': "_$rapyd$_eslice"
                        }),
                        'args': [expr].concat(slice_bounds),
                        'end': prev()
                    }), allow_calls)
                else:
                    # regular slice (arr[start:end])
                    slice_bounds = [i is None ? new AST_Number({
                        'value': 0
                    }) : i for i in slice_bounds]
                    return subscripts(new AST_Call({
                        'start': start,
                        'expression': new AST_Dot({
                            'start': start,
                            'expression': expr,
                            'property': "slice",
                            'end': prev()
                        }),
                        'args': slice_bounds,
                        'end': prev()
                    }), allow_calls)
            else:
                # regular index (arr[index])
                if is_py_sub:
                    assignment = None
                    if is_("operator") and S.token.value is "=":
                        next()
                        assignment = expression(True)
                    return subscripts(new AST_ItemAccess({
                        'start': start,
                        'expression': expr,
                        'property': slice_bounds[0] or new AST_Number({
                            'value': 0
                        }),
                        'assignment':assignment,
                        'end': prev()
                    }), allow_calls)

                return subscripts(new AST_Sub({
                    'start': start,
                    'expression': expr,
                    'property': slice_bounds[0] or new AST_Number({
                        'value': 0
                    }),
                    'end': prev()
                }), allow_calls)

        if allow_calls and is_("punc", "(") and not S.token.nlb:
            S.in_parenthesized_expr = True
            next()
            if not expr.parens and get_class_in_scope(expr):
                # this is an object being created using a class
                ret = subscripts(new AST_New({
                    'start': start,
                    'expression': expr,
                    'args': func_call_list(),
                    'end': prev()
                }), True)
                S.in_parenthesized_expr = False
                return ret
            else:
                if isinstance(expr, AST_Dot):
                    c = get_class_in_scope(expr.expression)

                if c:
                    # generate class call
                    funcname = expr
                    if funcname.property is "__init__":
                        funcname.property = "constructor"

                    ret = subscripts(new AST_ClassCall({
                        'start': start,
                        "class": expr.expression,
                        'method': funcname.property,
                        "static": is_static_method(c, funcname.property),
                        'args': func_call_list(),
                        'end': prev()
                    }), True)
                    S.in_parenthesized_expr = False
                    return ret
                elif isinstance(expr, AST_SymbolRef):
                    tmp_ = expr.name
                    # special functions that trigger addition of extra logic to generated JavaScript
                    if BASELIB_ITEMS.has(tmp_):
                        # NOTE: there is intentionally no return here, we want these functions to go through regular logic
                        # after they trigger the appropriate baselib flag
                        if BASELIB_FUNCS.has(tmp_):
                            baselib_items[tmp_ + '()'] = True
                        elif BASELIB_ITERTOOLS.has(tmp_):
                            baselib_items['itertools'] = True
                        else:
                            baselib_items[tmp_] = True
                    elif tmp_ is "type":
                        ret = new AST_UnaryPrefix({
                            'start': start,
                            'operator': "typeof",
                            'expression': func_call_list()[0],
                            'end': prev()
                        })
                        S.in_parenthesized_expr = False
                        return ret
                    elif tmp_ is "isinstance":
                        args = func_call_list()
                        if args.length is not 2:
                            croak('isinstance() must be called with exactly two arguments')
                        ret = new AST_Binary({
                            'start': start,
                            'left': args[0],
                            'operator': 'instanceof',
                            'right': args[1],
                            'end': prev()
                        })
                        S.in_parenthesized_expr = False
                        return ret

                # fall-through to basic function call
                ret = subscripts(new AST_Call({
                    'start': start,
                    'expression': expr,
                    'args': func_call_list(),
                    'end': prev()
                }), True)
                S.in_parenthesized_expr = False
                return ret

        return expr

    def maybe_unary(allow_calls):
        start = S.token
        if is_('operator', '@'):
            if S.parsing_decorator:
                croak('Nested decorators are not allowed')
            next()
            S.parsing_decorator = True
            expr = expression()
            S.parsing_decorator = False
            S.decorators.push(expr)
            return new AST_EmptyStatement({'stype':'@', 'start':prev(), 'end':prev()})
        if is_("operator") and UNARY_PREFIX(start.value):
            next()
            ex = make_unary(AST_UnaryPrefix, start.value, maybe_unary(allow_calls))
            ex.start = start
            ex.end = prev()
            return ex

        val = expr_atom(allow_calls)
        while is_("operator") and UNARY_POSTFIX(S.token.value) and not S.token.nlb:
            val = make_unary(AST_UnaryPostfix, S.token.value, val)
            val.start = start
            val.end = S.token
            next()
        return val

    def make_unary(ctor, op, expr):
        return new ctor({
            'operator': op,
            'expression': expr
        })

    def expr_op(left, min_prec, no_in):
        op = (is_("operator") ? S.token.value : None)
        not_in = False
        if op is "!" and peek().type is "operator" and peek().value is "in":
            next()
            op = "in"
            not_in = True

        if op is "in":
            if no_in:
                op = None
            else:
                baselib_items['_$rapyd$_in()'] = True

        prec = (op is not None ? PRECEDENCE[op] : None)
        if prec is not None and prec > min_prec:
            next()
            right = expr_op(maybe_unary(True), prec, no_in)
            ret = new AST_Binary({
                'start': left.start,
                'left': left,
                'operator': op,
                'right': right,
                'end': right.end
            })
            if not_in:
                ret = new AST_UnaryPrefix({
                    'start': left.start,
                    'operator': "!",
                    'expression': ret,
                    'end': right.end
                })
            return expr_op(ret, min_prec, no_in)
        return left

    def expr_ops(no_in):
        return expr_op(maybe_unary(True), 0, no_in)

    def maybe_conditional(no_in):
        start = S.token
        expr = expr_ops(no_in)
        if is_("operator", "?") or (is_('keyword', 'if') and (S.in_parenthesized_expr or (S.statement_starting_token is not S.token and not S.in_comprehension and not S.token.nlb))):
            pystyle = is_('keyword', 'if')
            next()
            ne = expression(False)
            if pystyle:
                expect_token('keyword', 'else')
                conditional = new AST_Conditional({
                    'start': start,
                    'condition': ne,
                    'consequent': expr,
                    'alternative': expression(False, no_in),
                    'end': peek()
                })
            else:
                yes = ne
                expect(":")
                conditional = new AST_Conditional({
                    'start': start,
                    'condition': expr,
                    'consequent': yes,
                    'alternative': expression(False, no_in),
                    'end': peek()
                })
            return conditional
        return expr

    def create_assign(data):
        if data.right and isinstance(data.right, AST_Seq) and (
                isinstance(data.right.car, AST_Assign) or
                isinstance(data.right.cdr, AST_Assign)) and data.operator is not '=':
            token_error(data.start, 'Invalid assignment operator for chained assignment: ' + data.operator)
        return new AST_Assign(data)

    def maybe_assign(no_in, only_plain_assignment):
        start = S.token
        left = maybe_conditional(no_in)
        val = S.token.value
        if is_("operator") and ASSIGNMENT(val):
            if only_plain_assignment and val is not '=':
                croak('Invalid assignment operator for chained assignment: ' + val)
            next()
            return create_assign({
                'start': start,
                'left': left,
                'operator': val,
                'right': maybe_assign(no_in, True),
                'end': prev()
            })
        return left

    def expression(commas, no_in):
        # if there is an assignment, we want the sequences to pivot
        # around it to allow for tuple packing/unpacking
        start = S.token
        expr = maybe_assign(no_in)
        def build_seq(a):
            if a.length is 1:
                return a[0]

            return new AST_Seq({
                'start': start,
                'car': a.shift(),
                'cdr': build_seq(a),
                'end': peek()
            })
        if commas:
            left = v'[ expr ]'
            while is_("punc", ",") and not peek().nlb:
                next()
                if isinstance(expr, AST_Assign):
                    left[-1] = left[-1].left
                    return create_assign({
                        'start': start,
                        'left': (left.length is 1 ? left[0] : new AST_Array({
                            'elements': left
                        })),
                        'operator': expr.operator,
                        'right': new AST_Seq({
                            'car': expr.right,
                            'cdr': expression(True, no_in)
                        }),
                        'end': peek()
                    })

                expr = maybe_assign(no_in)
                left.push(expr)

            # if last one was an assignment, fix it
            if left.length > 1 and isinstance(left[-1], AST_Assign):
                left[-1] = left[-1].left
                return create_assign({
                    'start': start,
                    'left': new AST_Array({
                        'elements': left
                    }),
                    'operator': expr.operator,
                    'right': expr.right,
                    'end': peek()
                })

            return build_seq(left)
        return expr

    def in_loop(cont):
        S.in_loop += 1
        ret = cont()
        S.in_loop -= 1
        return ret

    def run_parser():
        start = S.token = next()
        body = []
        first_token = True
        while not is_("eof"):
            element = statement()
            if first_token and isinstance(element, AST_Directive) and element.value.indexOf('#!') is 0:
                shebang = element.value
            else:
                body.push(element)
            first_token = False

        end = prev()
        toplevel = options.toplevel
        if toplevel:
            toplevel.body = toplevel.body.concat(body)
            toplevel.end = end
        else:
            toplevel = new AST_Toplevel({
                'start': start,
                'body': body,
                'shebang': shebang,
                'end': end
            })

        toplevel.nonlocalvars = scan_for_nonlocal_defs(toplevel.body)
        toplevel.localvars = []
        toplevel.exports = []
        seen_exports = {}

        def add_item(item, isvar):
            if (toplevel.nonlocalvars.indexOf(item) < 0):
                symbol = new_symbol(AST_SymbolVar, item)
                if isvar:
                    toplevel.localvars.push(symbol)
                if not Object.prototype.hasOwnProperty.call(seen_exports, item):
                    toplevel.exports.push(symbol)
                    seen_exports[item] = True

        scan_for_local_vars(toplevel.body).forEach(def(item): add_item(item, True);)
        scan_for_top_level_callables(toplevel.body).forEach(def (item): add_item(item, False);)

        toplevel.filename = options.filename
        toplevel.submodules = []
        toplevel.imported_module_ids = imported_module_ids
        toplevel.classes = scan_for_classes(toplevel.body)
        toplevel.import_order = Object.keys(imported_modules).length
        toplevel.module_id = module_id
        imported_modules[module_id] = toplevel
        toplevel.imports = imported_modules
        toplevel.baselib = baselib_items
        importing_modules[module_id] = False
        return toplevel

    return run_parser

def parse(text, options):
    options = defaults(options, {
        'filename': None,     # name of the file being parsed
        'auto_bind': False,   # whether auto-binding of methods to classes is enabled
        'module_id':'__main__', # The id of the module being parsed
        'toplevel': None,
        'for_linting': False, # If True certain actions are not performed, such as importing modules
        'import_dirs': v'[]',
        'classes': undefined  # Map of class names to AST_Class that are available in the global namespace (used by the REPL)
    })
    import_dirs = [x for x in options.import_dirs]
    for location in v'[options.libdir, options.basedir]':
        if location:
            import_dirs.push(location)
    module_id = options.module_id
    baselib_items = {}
    imported_module_ids = []
    imported_modules = options.imported_modules or {}
    importing_modules = options.importing_modules or {}
    importing_modules[module_id] = True

    # The internal state of the parser
    S = {
        'input': tokenizer(text, options.filename) if type(text) is 'string' else text,
        'token': None,
        'prev': None,
        'peeked': [],
        'in_function': 0,
        'in_directives': True,
        'statement_starting_token': None,
        'in_comprehension': False,
        'in_parenthesized_expr': False,
        'in_loop': 0,
        'in_class': [ False ],
        'classes': [ {} ],
        'functions': [ {} ],
        'labels': [],
        'decorators': v'[]',
        'parsing_decorator': False,
    }

    if options.classes:
        for cname in options.classes:
            obj = options.classes[cname]
            S.classes[0][cname] = { 'static':obj.static, 'bound':obj.bound }

    return create_parser_ctx(S, import_dirs, module_id, baselib_items, imported_module_ids, imported_modules, importing_modules, options)()
